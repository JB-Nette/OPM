{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oligopaints based MERFISH probe sequence design pipeline \n",
    "  \n",
    "The goal of this pipeline is to take a set of genes and use [OligoPaints](https://oligopaints.hms.harvard.edu/genome-files) for encoding probes, [DNA barcodes](https://elledge.hms.harvard.edu/?page_id=638) for readout probes/primers, and [5x5 bDNA sequences](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-019-43943-8/MediaObjects/41598_2019_43943_MOESM2_ESM.xlsx) for signal amplification. Signal amplification is necessary because the number of probes for many of our genes of interest are significantly less than the 92 probes used in the original MERFISH papers. The rules for our pipeline are assembled from all of the various MERFISH publications by Rory Kruithoff.  \n",
    "  \n",
    "Written on Ubuntu 18.04 LTS (both native and using Windows Subsytem). This code requires a working local BLAST install, working local BEDtools install, and some work to get cruzdb running with Python 3.x. Will write up the install in an another markdown once everything is finalized.\n",
    "\n",
    "Current external dependcies:\n",
    "- local BLAST install\n",
    "- local BEDTOOLS install\n",
    "  \n",
    "Current library dependencies:\n",
    "- python = 3.6\n",
    "- cruzdb (requires some effort to install in python 3.6)\n",
    "- pandas  \n",
    "- pybedtools  \n",
    "- biopython  \n",
    "- numpy  \n",
    "- os  \n",
    "  \n",
    "Current external data dependencies:\n",
    "- hg38 OligoPaints BED files  \n",
    "- hg38 transcriptome fasta file  \n",
    "- hg38 ncRNA fasta file  \n",
    "- Elledge lab 240k list of 25-mer sequences\n",
    "- Zhuang lab modified hamming codes  \n",
    "- Wollman lab modified hamming codes\n",
    "- Zhuang lab standard readout sequences\n",
    "- Moffitt & Zhuang lab amplified readout sequences \n",
    "\n",
    "Douglas Shepherd, PhD  \n",
    "Quantitative Imaging and Inference Lab (qi2lab)  \n",
    "Center for Biological Physics and Department of Physics  \n",
    "Arizona State University  \n",
    "04.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cruzdb imports\n",
    "# # https://github.com/brentp/cruzdb/tree/pull16/cruzdb\n",
    "from cruzdb import Genome \n",
    "\n",
    "# pandas imports\n",
    "# https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "# pybedtools imports\n",
    "# https://daler.github.io/pybedtools/\n",
    "# relies on a local BEDTOOLS installation\n",
    "import pybedtools \n",
    "\n",
    "# biopython imports\n",
    "# https://biopython.org/\n",
    "# relies on a local BLASTx installation\n",
    "from Bio import SeqIO\n",
    "from Bio import SearchIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import generic_dna\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.SeqUtils import GC as gcCheck\n",
    "from Bio.Blast.Applications import NcbimakeblastdbCommandline\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline as blastn\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "# numpy imports\n",
    "import numpy as np\n",
    "\n",
    "# os imports\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding probe design \n",
    "1. Define genes using refGene name from UCSC browser\n",
    "2. Pull all isoforms from UCSC associated with refGene name\n",
    "3. Parse out exons for each isoform.\n",
    "4. Using OligoPaints 'balanced' database to select probes for each isoform.\n",
    "5. Find unique probes that span all isoforms. Save probes in Pandas structure and a BLAST database\n",
    "6. If less than 30 probes, tag gene for multiple copies of readout sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take a dataframe of chromosome, exon locations, and strandness for one gene isoform and return a BED file \n",
    "def dfToBEDisoform(df_isoform):\n",
    "\n",
    "    # loop over each exon and create list of strings with format\n",
    "    # CHR START STOP NAME STRAND\n",
    "    bed_record=[]\n",
    "    i=0\n",
    "    for index, row in df_isoform.iterrows():\n",
    "        line=(str(row['chromosome']),str(row['start']),str(row['stop']),\n",
    "              gene_id+'_exon_'+str(row['exon']),0,str(row['strand']))\n",
    "        bed_record.append(line)\n",
    "        i+=1\n",
    "\n",
    "    # convert list of strings to BED record\n",
    "    BED_isoform = pybedtools.BedTool(bed_record)\n",
    "\n",
    "    # return BED record\n",
    "    return BED_isoform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take an isoform and return a set of probes\n",
    "def findProbesFromIsoform(gene_id,df_isoform,isoform_number):\n",
    "    \n",
    "    # convert dataframe to BED record\n",
    "    BED_isoform = dfToBEDisoform(df_isoform)\n",
    "    \n",
    "    # load OligoPaints BED file corresponding to chromosome for gene\n",
    "    BED_all_probes =pybedtools.BedTool('oligodb/hg38b/hg38_'+str(df_isoform.chromosome.unique()[0])+'b.bed')\n",
    "    \n",
    "    # find probes using intersect\n",
    "    encoding_probes = BED_all_probes.intersect(BED_isoform,f=1)\n",
    "    \n",
    "    # turn output into a list of strings\n",
    "    # check if strand is + or -\n",
    "    # if +, store probe\n",
    "    # if -, take reverse complement before storing probe\n",
    "    encoding_probes_sequence = []\n",
    "    for interval in encoding_probes:\n",
    "        if df_isoform.strand.unique()[0]=='+':\n",
    "            encoding_probes_sequence.append(interval.name)\n",
    "        else:\n",
    "            temp_seq = Seq(interval.name, generic_dna)\n",
    "            encoding_probes_sequence.append(str(temp_seq.reverse_complement()))\n",
    "        \n",
    "    # convert list of strings into dataframe\n",
    "    i=0\n",
    "    df_isoform_probes = pd.DataFrame(columns=['gene','isoform','probe','sequence'])\n",
    "    for probe_seq in encoding_probes_sequence:\n",
    "        df_isoform_probes = df_isoform_probes.append({'gene': gene_id, 'isoform': isoform_number,'probe': i,\n",
    "                                             'sequence': probe_seq},ignore_index=True)\n",
    "        i+=1\n",
    "    \n",
    "    # return dataframe for probes for this gene\n",
    "    return df_isoform_probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve exons from UCSC for a refGene ID\n",
    "def generateEncodingProbes(database, gene_ids):\n",
    "\n",
    "    # open connection to UCSC database\n",
    "    # here, we use the hg38 human genome assembly\n",
    "    g = Genome(db=genome)\n",
    "\n",
    "    # create empty dataframe to store all probes\n",
    "    df_encoding_probes = pd.DataFrame(columns=['gene','probe','sequence'])\n",
    "\n",
    "    # create empty dataframe\n",
    "    df_encoding_across_all_isoforms = pd.DataFrame(columns=['gene','isoform','probe','sequence'])\n",
    "\n",
    "    # loop over all genes\n",
    "    for gene_id in gene_ids:\n",
    "\n",
    "        # pull all entries for a given gene from UCSC\n",
    "        gene_entry_all = g.refGene.filter_by(name2=gene_id).all()\n",
    "\n",
    "        j=0\n",
    "        # loop over all gene entries\n",
    "        for isoform in gene_entry_all:\n",
    "\n",
    "            # extract exons for this gene entry\n",
    "            exons=isoform.exons\n",
    "\n",
    "            # create empty dataframe\n",
    "            df_exons = pd.DataFrame(columns=['gene','chromosome','exon','start','stop','strand'])\n",
    "\n",
    "            # place each exon in dataframe \n",
    "            i=0\n",
    "            for exon in exons:\n",
    "                df_exons = df_exons.append({'gene': gene_id, 'chromosome': isoform.chrom, \n",
    "                                           'exon': i, 'start': exon[0], 'stop': exon[1], 'strand': isoform.strand},\n",
    "                                          ignore_index=True)\n",
    "                i+=1\n",
    "\n",
    "            df_encoding_isoform=findProbesFromIsoform(gene_id,df_exons,j)\n",
    "            j+=1\n",
    "\n",
    "            df_encoding_across_all_isoforms = df_encoding_across_all_isoforms.append(df_encoding_isoform,ignore_index=True)\n",
    "\n",
    "    df_encoding_unique = df_encoding_across_all_isoforms.drop_duplicates(['sequence'])\n",
    "    df_encoding_unique=df_encoding_unique.reset_index()\n",
    "\n",
    "    # place this into the larger dataframe\n",
    "    df_encoding_probes=df_encoding_probes.append(df_encoding_unique,ignore_index=True)\n",
    "    df_encoding_probes=df_encoding_probes.drop(columns=['probe','index'])\n",
    "\n",
    "    return df_encoding_probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target genome\n",
    "genome = 'hg38'\n",
    "\n",
    "# define target genes\n",
    "# use refGene ID is UCSC\n",
    "# TO DO: create function to parse & load output of gene selection software\n",
    "'''\n",
    "gene_ids=['ACTA1','ACTA2','NOS3','VEGFA','VEGFB',\n",
    "          'VEGFC','VEGFD','KDR','HIF1A','EPAS1','HIF3A',\n",
    "          'IGF1','IGF1R','HGF','ALK','COL18A1',\n",
    "          'BMPR1A','CD34','VWF','KRT18','ACE2',\n",
    "          'RPTOR','RICTOR','MTOR','PIK3CA','SFTPB',\n",
    "          'SFTPC','EPCAM','MYRF','TMPRSS2','CTSL',\n",
    "          'POL1A','POL2A']\n",
    "'''\n",
    "\n",
    "gene_ids = ['VEGFA','NOS3']\n",
    "\n",
    "df_encoding=generateEncodingProbes(genome, gene_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse non-coding RNA FASTA\n",
    "1. [Download hg38 ncRNA fasta](ftp://ftp.ensembl.org/pub/release-99/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz)\n",
    "2. Parse out 'tRNA', 'Mt-tRNA', 'rRNA'\n",
    "3. Create blast database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastaToBlastDBncRNA():\n",
    "\n",
    "    records_to_keep=[]\n",
    "    with open('/home/dps/merfish/blastdb/tRNA/Homo_sapiens.GRCh38.ncrna.fa', 'r') as handle:\n",
    "        for record in SeqIO.parse(handle, 'fasta'):\n",
    "            description=record.description\n",
    "            if ('tRNA' in description) or ('rRNA' in description):\n",
    "                records_to_keep.append(record)\n",
    "                \n",
    "    with open('/home/dps/merfish/blastdb/tRNA/tRNA_parsed.fa','a') as output_handle:\n",
    "        for record in records_to_keep:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "    \n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/tRNA/tRNA_parsed.fa',\n",
    "                                       title='tRNA',out='/home/dps/merfish/blastdb/tRNA/db/tRNA')\n",
    "    stdout, stderr = cline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastaToBlastDBncRNA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denovo readout probe design\n",
    "1. Create set of all potential 20-mer readout probes from [known set](https://doi.org/10.1073/pnas.0812506106) of 240,000 25-mers.\n",
    "2. Select probes with only 'A', 'T', and 'C'.\n",
    "3. Select probes without 'CCC', 'AAA', and 'TTT'.\n",
    "4. Select probes with 40-50% GC content.\n",
    "5. BLAST 20-mers against transcriptome for species of interest. Select those with less than 11 contiguous base homology.\n",
    "6. BLAST 20-mers aganist tRNA, rRNA for species of interest and mitochondria. Select those with less than 11 contiguous base homology.\n",
    "7. BLAST 20-mers against other selected 20-mers. Select those with less than 11 contiguous base homology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDenovoReadoutProbes():\n",
    "    big_list_25mers_all = list(SeqIO.parse('bc25mer.240k.fasta','fasta'))\n",
    "    big_list_25mers=[]\n",
    "    \n",
    "    for i in range(0,len(big_list_25mers_all)):\n",
    "        big_list_25mers.append(str(big_list_25mers_all[i].seq))\n",
    "        \n",
    "    K=20\n",
    "    big_list_20mers=[]\n",
    "        \n",
    "    for trial_25mer in big_list_25mers:\n",
    "        trial_20mers = [trial_25mer[i: j] for i in range(len(trial_25mer)) for j in range(i + 1, len(trial_25mer) + 1) if len(trial_25mer[i:j]) == K]\n",
    "        for trial_20mer in trial_20mers:\n",
    "            if not ('G' in trial_20mer):\n",
    "                #trial_20mer.replace('C','G')\n",
    "                big_list_20mers.append(trial_20mer)\n",
    "            \n",
    "    pass_list=[]\n",
    "    for probe in big_list_20mers:\n",
    "        if not (('CCC' in probe) or ('TTT' in probe) or ('AAA' in probe)):\n",
    "            pass_list.append(probe)\n",
    "                \n",
    "    pass_list2=[]\n",
    "    for probe in pass_list:\n",
    "        gc_count = gcCheck(probe)\n",
    "\n",
    "        if (gc_count>=40) and (gc_count<=50):\n",
    "            pass_list2.append(probe)\n",
    "    \n",
    "    pass_list3=[]\n",
    "    for probe in pass_list2:\n",
    "\n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "        \n",
    "        with open('readout_test_h3g8.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='readout_test_h3g8.fasta',db='/home/dps/merfish/blastdb/hg38/GRCh38',\n",
    "                              out='readout_check_hg38.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_check_hg38.xml','r') as input_handle_hg38:\n",
    "            blast_qresult = SearchIO.read(input_handle_hg38, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult:\n",
    "            if (hit.seq_len>=10):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list3.append(probe)\n",
    "            \n",
    "    pass_list4=[]\n",
    "    first = True\n",
    "    for probe in pass_list3:\n",
    "\n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "        \n",
    "        with open('readout_test_ncRNA.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='readout_test_ncRNA.fasta',db='/home/dps/merfish/blastdb/tRNA/db/tRNA',\n",
    "                              out='readout_check_ncRNA.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_check_ncRNA.xml','r') as input_handle_ncRNA:\n",
    "            blast_qresult_ncRNA = SearchIO.read(input_handle_ncRNA, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_ncRNA:\n",
    "            if (hit.seq_len>=10):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list4.append(probe)\n",
    "            \n",
    "    for probe in pass_list4:\n",
    "        \n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i),description=\"potential readout \"+str(i))\n",
    "\n",
    "        with open('/home/dps/merfish/blastdb/readout/readout_candidates.fasta','a') as output_handle:    \n",
    "            SeqIO.write(record,output_handle,\"fasta\")\n",
    "\n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/readout/readout_candidates.fasta',\n",
    "                                       title='readout',out='/home/dps/merfish/blastdb/readout/db/readout')\n",
    "    stdout, stderr = cline()\n",
    "                \n",
    "    pass_list5=[]\n",
    "    for probe in pass_list4:\n",
    "\n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "        \n",
    "        with open('readout_test_final.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='readout_test_final.fasta',db='/home/dps/merfish/blastdb/readout/db/readout',\n",
    "                              out='readout_test_final.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_test_final.xml','r') as input_handle_final:\n",
    "            blast_qresult_final = SearchIO.read(input_handle_final, 'blast-xml')\n",
    "        \n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_final:\n",
    "            if (hit.seq_len>=10) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list5.append(probe)\n",
    "    \n",
    "    # place each probe in dataframe \n",
    "    df_readout_probes = pd.DataFrame(columns=['probe','sequence'])\n",
    "    i=0\n",
    "    for probe in pass_list5:\n",
    "        df_readout_probes = df_readout.append({'probe': i, 'sequence': probe},ignore_index=True)\n",
    "        i+=1\n",
    "        \n",
    "    return df_readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_readout_probes=generateDenovoReadoutProbes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published standard readout sequences\n",
    "1. Load readout sequences used for 16-bit MHD4 code from [Moffitt et al 2018](https://doi.org/10.1073/pnas.1617699113).  \n",
    "  \n",
    "Moffitt et al used 'A','T','G' instead of the 'A','T','C' strategy used for our denovo readout sequence design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadReadoutSequences():\n",
    "    \n",
    "    df_readout_probes = pd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published amplified readout sequences \n",
    "1. Load 5x5 amplified readout sequences for 16-bit MHD4 code from [Xia et al 2019](https://doi.org/10.1038/s41598-019-43943-8).\n",
    "\n",
    "This is a clear area of opportunity. Look into orthogonal strategies used in [SABER](https://www.nature.com/articles/s41592-019-0404-0#Sec36). I agree with Moffitt that solid-phase amplifiers with defined number of binding sites makes more sense as it will reduce variation. Even if it does cost a little bit extra. Also, Allen has not been able to reliable run the SABER reaction to get amplifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAmplifiedReadoutSequences():\n",
    "    \n",
    "    df_readout_probes_amplified = pd.read_excel('/home/dps/merfish/16bit_MHD4_amplify.xlsx',header=1)\n",
    "    \n",
    "    return df_readout_probes_amplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published modified hamming codes\n",
    "Load:\n",
    "1. 14-bit modified hamming codes from [Zhuang lab example data #1](http://zhuang.harvard.edu/merfish.html).\n",
    "2. 16-bit modified hamming codes from [Zhuang lab example data #1](http://zhuang.harvard.edu/merfish.html).\n",
    "3. 18-bit modified hamming codes from [Wollman MERFISH github repo](https://github.com/wollmanlab/PySpots).\n",
    "4. 24-bit modified hamming codes from [Wollman MERFISH github repo](https://github.com/wollmanlab/PySpots).  \n",
    "  \n",
    "This is a clear area of opportunity. We are working on alternative coding/decoding at ASU, but are not ready to roll it out yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadHammingFromDisk(bit):\n",
    "\n",
    "    if (bit=='14-bit'):\n",
    "        list_hamming=[]\n",
    "        with open('/home/dps/merfish/codebook/14bit_MHD2_codebook.fasta','r') as input_handle:\n",
    "            for record in SeqIO.parse(input_handle, 'fasta'):\n",
    "                list_hamming.append(record.description.split())\n",
    "\n",
    "        df_hamming_codes=pd.DataFrame(list_hamming,columns=['R0','R1','R2','R3',\n",
    "                                                        'R4','R5','R6','R7',\n",
    "                                                        'R8','R9','R10','R11',\n",
    "                                                        'R12','R13'])\n",
    "    else if (bit=='16-bit'):\n",
    "        list_codebook=[]\n",
    "        with open('/home/dps/merfish/codebook/16bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            for record in SeqIO.parse(input_handle, 'fasta'):\n",
    "                list_hamming.append(record.description.split())\n",
    "\n",
    "        df_hamming_codes=pd.DataFrame(list_hamming,columns=['R0','R1','R2','R3',\n",
    "                                                        'R4','R5','R6','R7',\n",
    "                                                        'R8','R9','R10','R11',\n",
    "                                                        'R12','R13','R14','R15'])\n",
    "        \n",
    "    else if (bit=='18-bit'):\n",
    "        list_codebook=[]\n",
    "        df_hamming_codes=pd.DataFrame(columns=['R0','R1','R2','R3',\n",
    "                                               'R4','R5','R6','R7',\n",
    "                                               'R8','R9','R10','R11',\n",
    "                                               'R12','R13','R14','R15',\n",
    "                                               'R16','R17'])\n",
    "        with open('/home/dps/merfish/codebook/18bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            df_hamming_codes=pd.read_csv(input_handle,delimeter=',')\n",
    "                \n",
    "    else:\n",
    "        list_codebook=[]\n",
    "        df_hamming_codes=pd.DataFrame(columns=['R0','R1','R2','R3',\n",
    "                                               'R4','R5','R6','R7',\n",
    "                                               'R8','R9','R10','R11',\n",
    "                                               'R12','R13','R14','R15',\n",
    "                                               'R16','R17','R18','R19',\n",
    "                                               'R20','R21','R22','R23'])\n",
    "        with open('/home/dps/merfish/codebook/24bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            df_hamming_codes=pd.read_csv(input_handle,delimeter=',')\n",
    "            \n",
    "    return df_hamming_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hamming_codes = loadCodebookFromDisk('16-bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denovo primer design\n",
    "1. Read (or create) set of 20-mers from known set of 25-mers\n",
    "2. BLAST 20-mers against encoding+readout probes. Select all probes with less than 10 hits.\n",
    "3. BLAST 20-mers against lincRNA, rRNA, tRNA, mt-tRNA, mt-RNA for species of interest. Select all probes with less than 10 hits.\n",
    "3. Select forward and reverse primer based on minimum number of off-target hits.\n",
    "4. Save primers into Pandas structure separately and as sets with encoding+readout probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePrimers(df_probes):\n",
    "\n",
    "    big_list_25mers_all = list(SeqIO.parse('bc25mer.240k.fasta','fasta'))\n",
    "    big_list_25mers=[]\n",
    "    \n",
    "    for i in range(0,len(big_list_25mers_all)):\n",
    "        big_list_25mers.append(str(big_list_25mers_all[i].seq))\n",
    "        \n",
    "    K=20\n",
    "    big_list_20mers=[]\n",
    "        \n",
    "    for trial_25mer in big_list_25mers:\n",
    "        trial_20mers = [trial_25mer[i: j] for i in range(len(trial_25mer)) for j in range(i + 1, len(trial_25mer) + 1) if len(trial_25mer[i:j]) == K]\n",
    "        for trial_20mer in trial_20mers:\n",
    "            if (trial_20mer.endswith('G') or trial_20mer.endswith('C') \n",
    "                or str(trial_20mer[:-1]).endswith('G') or str(trial_20mers[:-1]).endswith('C')):\n",
    "                    big_list_20mers.append(trial_20mer)\n",
    "            \n",
    "    pass_list=[]\n",
    "    for primer in big_list_20mers:\n",
    "        if not (('CCC' in primer) or ('TTT' in primer) or ('AAA' in primer) or ('GGG' in primer)):\n",
    "            pass_list.append(primer)\n",
    "                \n",
    "    pass_list2=[]\n",
    "    for primer in pass_list:\n",
    "        gc_count = gcCheck(primer)\n",
    "\n",
    "        if (gc_count>=40) and (gc_count<=50):\n",
    "            pass_list2.append(primer)\n",
    "            \n",
    "    pass_list3=[]\n",
    "    for primer in pass_list2:\n",
    "        tmval = mt.Tm_NN(primer,Na=300,dnac1=25,dnac2=0)\n",
    "        if (tmval>=70.0) and (tmval<=80.0):\n",
    "                pass_list.append(primer)\n",
    "    \n",
    "    pass_list4=[]\n",
    "    for primer in pass_list3:\n",
    "\n",
    "        record = SeqRecord(Seq(primer,generic_dna),id=primer+'_'+str(i))\n",
    "        \n",
    "        with open('primer_test_h3g8.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='primer_test_h3g8.fasta',db='/home/dps/merfish/blastdb/hg38/GRCh38',\n",
    "                              out='primer_check_hg38.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('primer_check_hg38.xml','r') as input_handle_hg38:\n",
    "            blast_qresult = SearchIO.read(input_handle_hg38, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult:\n",
    "            if (hit.seq_len>=10):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list4.append(primer)\n",
    "            \n",
    "    pass_list5=[]\n",
    "    first = True\n",
    "    for primer in pass_list4:\n",
    "\n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "        \n",
    "        with open('primer_test_ncRNA.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='primer_test_ncRNA.fasta',db='/home/dps/merfish/blastdb/tRNA/db/tRNA',\n",
    "                              out='primer_check_ncRNA.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('primer_check_ncRNA.xml','r') as input_handle_ncRNA:\n",
    "            blast_qresult_ncRNA = SearchIO.read(input_handle_ncRNA, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_ncRNA:\n",
    "            if (hit.seq_len>=10):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list5.append(primer)\n",
    "            \n",
    "    for primer in pass_list5:\n",
    "        \n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i),description=\"potential primer \"+str(i))\n",
    "\n",
    "        with open('/home/dps/merfish/blastdb/primer/primer_candidates.fasta','a') as output_handle:    \n",
    "            SeqIO.write(record,output_handle,\"fasta\")\n",
    "\n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/primer/primer_candidates.fasta',\n",
    "                                       title='primer',out='/home/dps/merfish/blastdb/primer/db/primer')\n",
    "    stdout, stderr = cline()\n",
    "                \n",
    "    pass_list6=[]\n",
    "    for primer in pass_list5:\n",
    "\n",
    "        record = SeqRecord(Seq(primer,generic_dna),id=probe+'_'+str(i))\n",
    "        \n",
    "        with open('primer_test_final.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='primer_test_final.fasta',db='/home/dps/merfish/blastdb/primer/db/primer',\n",
    "                              out='primer_test_final.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('primer_test_final.xml','r') as input_handle_final:\n",
    "            blast_qresult_final = SearchIO.read(input_handle_final, 'blast-xml')\n",
    "        \n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_final:\n",
    "            if (hit.seq_len>=10) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list5.append(probe)\n",
    "    \n",
    "    # place each probe in dataframe \n",
    "    df_readout_probes = pd.DataFrame(columns=['probe','sequence'])\n",
    "    i=0\n",
    "    for probe in pass_list5:\n",
    "        df_readout_probes = df_readout.append({'probe': i, 'sequence': probe},ignore_index=True)\n",
    "        i+=1\n",
    "        \n",
    "    return df_readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if potential primers dataframe is saved to disk\n",
    "# if true, load it\n",
    "# if not, generate it (need to add checks?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental design\n",
    "1. Create experiment specific codebook using two-colors, number of genes, and known codes from Zhuang lab.\n",
    "2. Assemble primers, encoding, and readout probes\n",
    "3. Save experiental design into the Pandas structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineCodebook():\n",
    "    \n",
    "    # automatically assign low probe count genes (<30) to Alexa647\n",
    "    \n",
    "    # randomly assign remaining genes between Cy3B and Alexa647\n",
    "    \n",
    "    # loop over all genes\n",
    "    \n",
    "    # randomly assign probes for each gene to readout set A (readouts round 1 & 3) and readout set B (readout rounds 2 & 4)\n",
    "    \n",
    "    # create codebook for a given gene\n",
    "    \n",
    "    # return codebook for panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructEncodingWithReadoutProbes():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructFullProbes():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define barcode strategy\n",
    "# 14-bit vs 16-bit\n",
    "hamming_bit = '16-bit'\n",
    "\n",
    "# define readout probe strategy\n",
    "# standard (3 readout per probe) vs amplified (2 readout per probe)\n",
    "# if standard, generate denovo probes or use known probes?\n",
    "readout_strategy = 'amplified'\n",
    "\n",
    "# define target genome\n",
    "genome = 'hg38'\n",
    "\n",
    "# define target genes\n",
    "# use refGene ID is UCSC\n",
    "# TO DO: isoform and/or exon specific targeting\n",
    "# TO DO: create function to parse & load output of gene selection software\n",
    "gene_ids=['ACTA1','ACTA2','NOS3','VEGFA','VEGFB',\n",
    "          'VEGFC','VEGFD','KDR','HIF1A','EPAS1','HIF3A',\n",
    "          'IGF1','IGF1R','HGF','ALK','COL18A1',\n",
    "          'BMPR1A','CD34','VWF','KRT18','ACE2',\n",
    "          'RPTOR','RICTOR','MTOR','PIK3CA','SFTPB',\n",
    "          'SFTPC','EPCAM','MYRF','TMPRSS2','CTSL',\n",
    "          'POL1A','POL2A']\n",
    "\n",
    "# load modified hamming codes\n",
    "df_barcodes = loadHammingFromDisk(bit)\n",
    "\n",
    "# load (or generate) readout probe sequences\n",
    "# TO DO: version tracking linked to specific readout probe orders\n",
    "df_readout_probes = loadReadoutProbes(readout_strategy)\n",
    "\n",
    "# generate encoding probe sequences\n",
    "df_encoding_probes = generateEncodingProbes(database,gene_ids)\n",
    "\n",
    "# generate codebook \n",
    "df_codebook = \n",
    "\n",
    "# generate encoding+readout probe sequences\n",
    "df_encoding_readout_probes = \n",
    "\n",
    "# generate forward and reverse primer sequences for this set of encoding+readout probes\n",
    "df_primers = \n",
    "\n",
    "# generate full probe sequences for ordering\n",
    "df_full_probes = \n",
    "\n",
    "# save all dataframes to disk with unique identifiers and all settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db='hg38'\n",
    "g = Genome(db=database)\n",
    "#obj = g.knownCanonical.filter_by(name=g.kgXref.geneSymbol('VEGFA')).first()\n",
    "objs=g.refGene.filter_by(name2=\"VEGFA\").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_isoforms=[]\n",
    "for obj in objs:\n",
    "        all_isoforms.append(list(obj.exons))\n",
    "        \n",
    "# using naive method  \n",
    "# to get list intersection \n",
    "res_list = [] \n",
    "for test_isoform_1 in all_isoforms:\n",
    "    for test_isoform_2 in all_isoforms:\n",
    "        for i in test_isoform_1: \n",
    "            if i in test_isoform_2:\n",
    "                res_list.append(i) \n",
    "\n",
    "temp=np.array(res_list)\n",
    "temp_uniq=np.unique(temp)\n",
    "print(temp_uniq[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
