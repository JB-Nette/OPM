{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oligopaints based MERFISH probe sequence design pipeline \n",
    "  \n",
    "The goal of this pipeline is to take a set of genes and use [OligoPaints](https://oligopaints.hms.harvard.edu/genome-files) for encoding probes, [DNA barcodes](https://elledge.hms.harvard.edu/?page_id=638) for readout probes/primers, and [5x5 bDNA sequences](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-019-43943-8/MediaObjects/41598_2019_43943_MOESM2_ESM.xlsx) for signal amplification. Signal amplification is necessary because the number of probes for many of our genes of interest are significantly less than the 96 probes used in the original MERFISH papers. The rules for our pipeline are assembled from all of the various MERFISH publications by Rory Kruithoff.  \n",
    "  \n",
    "Written on Ubuntu 18.04 LTS (both native and using Windows Subsytem). This code requires a working local BLAST install, working local BEDtools install, and some work to get cruzdb running with Python 3.x. Will write up the install in an another markdown once everything is finalized.\n",
    "\n",
    "Current external dependcies:\n",
    "- local [BLAST install](https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/)\n",
    "- local [BEDTOOLS install](https://bedtools.readthedocs.io/en/latest/content/installation.html)\n",
    "  \n",
    "Current library dependencies:\n",
    "- python = 3.6\n",
    "- cruzdb (requires some effort to install in python 3.6, need to use [pull request 16](https://github.com/brentp/cruzdb/pull/16))\n",
    "- pandas\n",
    "- pybedtools\n",
    "- biopython  \n",
    "- numpy  \n",
    "- os  \n",
    "  \n",
    "Current external data dependencies:\n",
    "- hg38 OligoPaints BED files  \n",
    "- hg38 transcriptome fasta file  \n",
    "- hg38 ncRNA fasta file  \n",
    "- Elledge lab 240k list of 25-mer sequences\n",
    "- Zhuang lab modified hamming codes  \n",
    "- Wollman lab modified hamming codes\n",
    "- Moffitt lab standard readout sequences\n",
    "- Moffitt lab amplified readout sequences \n",
    "\n",
    "Douglas Shepherd, PhD  \n",
    "Quantitative Imaging and Inference Lab (qi2lab)  \n",
    "Center for Biological Physics and Department of Physics  \n",
    "Arizona State University  \n",
    "04.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cruzdb imports\n",
    "# # https://github.com/brentp/cruzdb/tree/pull16/cruzdb\n",
    "from cruzdb import Genome \n",
    "\n",
    "# pandas imports\n",
    "# https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "# pybedtools imports\n",
    "# https://daler.github.io/pybedtools/\n",
    "# relies on a local BEDTOOLS installation\n",
    "import pybedtools \n",
    "\n",
    "# biopython imports\n",
    "# https://biopython.org/\n",
    "# relies on a local BLASTx installation\n",
    "from Bio import SeqIO\n",
    "from Bio import SearchIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import generic_dna\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.SeqUtils import GC as gcCheck\n",
    "from Bio.Blast.Applications import NcbimakeblastdbCommandline\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline as blastn\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "# numpy imports\n",
    "import numpy as np\n",
    "\n",
    "# os imports\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding probe design \n",
    "1. Define genes using refGene name from UCSC browser\n",
    "2. Pull all isoforms from UCSC associated with refGene name\n",
    "3. Parse out exons for each isoform.\n",
    "4. Using OligoPaints 'balanced' database to select probes for each isoform.\n",
    "5. Find unique probes that span all isoforms. Save probes in Pandas structure and a BLAST database\n",
    "6. If less than 30 probes, tag gene for multiple copies of readout sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take a dataframe of chromosome, exon locations, and strandness for one gene isoform and return a BED file \n",
    "def dfToBEDisoform(gene_id,df_isoform):\n",
    "\n",
    "    # loop over each exon and create list of strings with format\n",
    "    # CHR START STOP NAME STRAND\n",
    "    bed_record=[]\n",
    "    i=0\n",
    "    for index, row in df_isoform.iterrows():\n",
    "        line=(str(row['chromosome']),str(row['start']),str(row['stop']),\n",
    "              gene_id+'_exon_'+str(row['exon']),0,str(row['strand']))\n",
    "        bed_record.append(line)\n",
    "        i+=1\n",
    "\n",
    "    # convert list of strings to BED record\n",
    "    BED_isoform = pybedtools.BedTool(bed_record)\n",
    "\n",
    "    # return BED record\n",
    "    return BED_isoform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take an isoform and return a set of probes\n",
    "def findProbesFromIsoform(gene_id,df_isoform,isoform_number):\n",
    "    \n",
    "    # convert dataframe to BED record\n",
    "    BED_isoform = dfToBEDisoform(gene_id,df_isoform)\n",
    "    \n",
    "    # load OligoPaints BED file corresponding to chromosome for gene\n",
    "    BED_all_probes =pybedtools.BedTool('oligodb/hg38b/hg38_'+str(df_isoform.chromosome.unique()[0]).split('_')[0]+'b.bed')\n",
    "    \n",
    "    # find probes using intersect\n",
    "    encoding_probes = BED_all_probes.intersect(BED_isoform,f=1)\n",
    "    \n",
    "    # turn output into a list of strings\n",
    "    # check if strand is + or -\n",
    "    # if +, store probe\n",
    "    # if -, take reverse complement before storing probe\n",
    "    encoding_probes_sequence = []\n",
    "    for interval in encoding_probes:\n",
    "        if df_isoform.strand.unique()[0]=='+':\n",
    "            encoding_probes_sequence.append(interval.name)\n",
    "        else:\n",
    "            temp_seq = Seq(interval.name, generic_dna)\n",
    "            encoding_probes_sequence.append(str(temp_seq.reverse_complement()))\n",
    "        \n",
    "    # convert list of strings into dataframe\n",
    "    i=0\n",
    "    df_isoform_probes = pd.DataFrame(columns=['gene','isoform','probe','sequence'])\n",
    "    for probe_seq in encoding_probes_sequence:\n",
    "        df_isoform_probes = df_isoform_probes.append({'gene': gene_id, 'isoform': isoform_number,'probe': i,\n",
    "                                             'sequence': probe_seq},ignore_index=True)\n",
    "        i+=1\n",
    "    \n",
    "    # return dataframe for probes for this gene\n",
    "    return df_isoform_probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve exons from UCSC for a refGene ID\n",
    "def generateEncodingProbes(database, gene_ids):\n",
    "\n",
    "    # open connection to UCSC database\n",
    "    # here, we use the hg38 human genome assembly\n",
    "    g = Genome(db=genome)\n",
    "\n",
    "    # create empty dataframe to store all probes\n",
    "    df_encoding_probes = pd.DataFrame(columns=['gene','probe','sequence'])\n",
    "\n",
    "    # create empty dataframe\n",
    "    df_encoding_across_all_isoforms = pd.DataFrame(columns=['gene','isoform','probe','sequence'])\n",
    "\n",
    "    # loop over all genes\n",
    "    for gene_id in gene_ids:\n",
    "\n",
    "        # pull all entries for a given gene from UCSC\n",
    "        gene_entry_all = g.refGene.filter_by(name2=gene_id).all()\n",
    "\n",
    "        j=0\n",
    "        # loop over all gene entries\n",
    "        for isoform in gene_entry_all:\n",
    "\n",
    "            # extract exons for this gene entry\n",
    "            exons=isoform.exons\n",
    "\n",
    "            # create empty dataframe\n",
    "            df_exons = pd.DataFrame(columns=['gene','chromosome','exon','start','stop','strand'])\n",
    "\n",
    "            # place each exon in dataframe \n",
    "            i=0\n",
    "            for exon in exons:\n",
    "                df_exons = df_exons.append({'gene': gene_id, 'chromosome': isoform.chrom, \n",
    "                                           'exon': i, 'start': exon[0], 'stop': exon[1], 'strand': isoform.strand},\n",
    "                                          ignore_index=True)\n",
    "                i+=1\n",
    "\n",
    "            df_encoding_isoform=findProbesFromIsoform(gene_id,df_exons,j)\n",
    "            j+=1\n",
    "\n",
    "            df_encoding_across_all_isoforms = df_encoding_across_all_isoforms.append(df_encoding_isoform,ignore_index=True)\n",
    "\n",
    "    df_encoding_unique = df_encoding_across_all_isoforms.drop_duplicates(['sequence'])\n",
    "    df_encoding_unique=df_encoding_unique.reset_index()\n",
    "\n",
    "    # place this into the larger dataframe\n",
    "    df_encoding_probes=df_encoding_probes.append(df_encoding_unique,ignore_index=True)\n",
    "    df_encoding_probes=df_encoding_probes.drop(columns=['probe','index'])\n",
    "\n",
    "    return df_encoding_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse non-coding RNA FASTA\n",
    "1. [Download hg38 ncRNA fasta](ftp://ftp.ensembl.org/pub/release-99/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz)\n",
    "2. Parse out 'tRNA', 'Mt-tRNA', 'rRNA'\n",
    "3. Create blast database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastaToBlastDBncRNA():\n",
    "\n",
    "    records_to_keep=[]\n",
    "    with open('/home/dps/merfish/blastdb/tRNA/Homo_sapiens.GRCh38.ncrna.fa', 'r') as handle:\n",
    "        for record in SeqIO.parse(handle, 'fasta'):\n",
    "            description=record.description\n",
    "            if ('tRNA' in description) or ('rRNA' in description):\n",
    "                records_to_keep.append(record)\n",
    "                \n",
    "    with open('/home/dps/merfish/blastdb/tRNA/tRNA_parsed.fa','a') as output_handle:\n",
    "        for record in records_to_keep:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "    \n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/tRNA/tRNA_parsed.fa',\n",
    "                                       title='tRNA',out='/home/dps/merfish/blastdb/tRNA/db/tRNA')\n",
    "    stdout, stderr = cline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denovo readout probe design\n",
    "1. Create set of all potential 20-mer readout probes from [known set](https://doi.org/10.1073/pnas.0812506106) of 240,000 25-mers.\n",
    "2. Select probes with only 'A', 'T', and 'C'.\n",
    "3. Select probes without 'CCC', 'AAA', and 'TTT'.\n",
    "4. Select probes with 40-50% GC content.\n",
    "5. BLAST 20-mers against transcriptome for species of interest. Select those with less than 11 contiguous base homology.\n",
    "6. BLAST 20-mers aganist tRNA, rRNA for species of interest and mitochondria. Select those with less than 11 contiguous base homology.\n",
    "7. BLAST 20-mers against other selected 20-mers. Select those with less than 11 contiguous base homology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDenovoReadoutProbes():\n",
    "    \n",
    "    # Make sure non-coding RNA database exists\n",
    "    fastaToBlastDBncRNA()\n",
    "    \n",
    "    big_list_25mers_all = list(SeqIO.parse('bc25mer.240k.fasta','fasta'))\n",
    "    big_list_25mers=[]\n",
    "    \n",
    "    for i in range(0,len(big_list_25mers_all)):\n",
    "        big_list_25mers.append(str(big_list_25mers_all[i].seq))\n",
    "        \n",
    "    K=20\n",
    "    big_list_20mers=[]\n",
    "        \n",
    "    for trial_25mer in big_list_25mers:\n",
    "        trial_20mers = [trial_25mer[i: j] for i in range(len(trial_25mer)) for j in range(i + 1, len(trial_25mer) + 1) if len(trial_25mer[i:j]) == K]\n",
    "        for trial_20mer in trial_20mers:\n",
    "            if not ('G' in trial_20mer):\n",
    "                #trial_20mer.replace('C','G')\n",
    "                big_list_20mers.append(trial_20mer)\n",
    "            \n",
    "    pass_list=[]\n",
    "    for probe in big_list_20mers:\n",
    "        if not (('CCC' in probe) or ('TTT' in probe) or ('AAA' in probe)):\n",
    "            pass_list.append(probe)\n",
    "                \n",
    "    pass_list2=[]\n",
    "    for probe in pass_list:\n",
    "        gc_count = gcCheck(probe)\n",
    "\n",
    "        if (gc_count>=40) and (gc_count<=50):\n",
    "            pass_list2.append(probe)\n",
    "    \n",
    "    pass_list3=[]\n",
    "    for probe in pass_list2:\n",
    "\n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "        \n",
    "        with open('readout_test_h3g8.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='readout_test_h3g8.fasta',db='/home/dps/merfish/blastdb/hg38/GRCh38',\n",
    "                              out='readout_check_hg38.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_check_hg38.xml','r') as input_handle_hg38:\n",
    "            blast_qresult = SearchIO.read(input_handle_hg38, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult:\n",
    "            if (hit.seq_len>=10):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list3.append(probe)\n",
    "            \n",
    "    pass_list4=[]\n",
    "    first = True\n",
    "    for probe in pass_list3:\n",
    "\n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "        \n",
    "        with open('readout_test_ncRNA.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='readout_test_ncRNA.fasta',db='/home/dps/merfish/blastdb/tRNA/db/tRNA',\n",
    "                              out='readout_check_ncRNA.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_check_ncRNA.xml','r') as input_handle_ncRNA:\n",
    "            blast_qresult_ncRNA = SearchIO.read(input_handle_ncRNA, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_ncRNA:\n",
    "            if (hit.seq_len>=10):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list4.append(probe)\n",
    "            \n",
    "    for probe in pass_list4:\n",
    "        \n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i),description=\"potential readout \"+str(i))\n",
    "\n",
    "        with open('/home/dps/merfish/blastdb/readout/readout_candidates.fasta','a') as output_handle:    \n",
    "            SeqIO.write(record,output_handle,\"fasta\")\n",
    "\n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/readout/readout_candidates.fasta',\n",
    "                                       title='readout',out='/home/dps/merfish/blastdb/readout/db/readout')\n",
    "    stdout, stderr = cline()\n",
    "                \n",
    "    pass_list5=[]\n",
    "    for probe in pass_list4:\n",
    "\n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "        \n",
    "        with open('readout_test_final.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='readout_test_final.fasta',db='/home/dps/merfish/blastdb/readout/db/readout',\n",
    "                              out='readout_test_final.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_test_final.xml','r') as input_handle_final:\n",
    "            blast_qresult_final = SearchIO.read(input_handle_final, 'blast-xml')\n",
    "        \n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_final:\n",
    "            if (hit.seq_len>=10) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list5.append(probe)\n",
    "    \n",
    "    # place each probe in dataframe \n",
    "    df_readout_probes = pd.DataFrame(columns=['probe','sequence'])\n",
    "    i=0\n",
    "    for probe in pass_list5:\n",
    "        df_readout_probes = df_readout_probes.append({'probe': i, 'sequence': probe},ignore_index=True)\n",
    "        i+=1\n",
    "        \n",
    "    return df_readout_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published standard readout sequences\n",
    "1. Load readout sequences used for 16-bit MHD4 code from [Moffitt et al 2018](https://doi.org/10.1073/pnas.1617699113).\n",
    "2. Need to use reverse complement of these when assembling probes.\n",
    "  \n",
    "Moffitt et al used 'A','T','G' instead of the 'A','T','C' strategy used for our denovo readout sequence design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMoffittReadoutSequences():\n",
    "    \n",
    "    df_readout = pd.read_csv('/home/dps/merfish/16bit_MHD4_readout.tsv',sep='\\t',header=0,index_col='probe')\n",
    "    df_readout.reset_index(inplace=True)\n",
    "    \n",
    "    return df_readout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published amplified readout sequences \n",
    "1. Load 5x5 amplified readout sequences for 16-bit MHD4 code from [Xia et al 2019](https://doi.org/10.1038/s41598-019-43943-8).\n",
    "2. Need to use reverse complement of original readout sequences when assembling probes.\n",
    "3. Use final readout sequences as is with dye molecules on 3' end\n",
    "\n",
    "This is a clear area of opportunity. Look into orthogonal strategies used in [SABER](https://www.nature.com/articles/s41592-019-0404-0#Sec36). I agree with Moffitt that solid-phase amplifiers with defined number of binding sites makes more sense as it will reduce variation. Even if it does cost a little bit extra. Also, many groups I have talked to have not been able to successfully perform the SABER reaction to get amplifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAmplifiedReadoutSequences():\n",
    "    \n",
    "    df_readout_amplified = pd.read_excel('/home/dps/merfish/16bit_MHD4_amplify.xlsx',skip_row=0,header=1,index_col='Bit')\n",
    "    \n",
    "    return df_readout_amplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper function to load selected readout probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadReadoutProbes(readout_strategy):\n",
    "    \n",
    "    if readout_strategy=='denovo':\n",
    "        df_readout_probes=generateDenovoReadoutProbes()\n",
    "    elif readout_strategy=='standard':\n",
    "        df_readout_probes=loadMoffittReadoutSequences()\n",
    "    else:\n",
    "        df_readout_probes=loadAmplifiedReadoutSequences()\n",
    "        \n",
    "    return df_readout_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper function to load selected Hamming codes\n",
    "Load:\n",
    "1. 14-bit modified hamming codes from [Zhuang lab example data #1](http://zhuang.harvard.edu/merfish.html).\n",
    "2. 16-bit modified hamming codes from [Zhuang lab example data #1](http://zhuang.harvard.edu/merfish.html).\n",
    "3. 18-bit modified hamming codes from [Wollman MERFISH github repo](https://github.com/wollmanlab/PySpots).\n",
    "4. 24-bit modified hamming codes from [Wollman MERFISH github repo](https://github.com/wollmanlab/PySpots).  \n",
    "  \n",
    "This is a clear area of opportunity. We are working on alternative coding/decoding at ASU, but are not ready to roll it out yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadHammingFromDisk(bit):\n",
    "\n",
    "    if (bit=='14-bit'):\n",
    "        list_hamming=[]\n",
    "        with open('/home/dps/merfish/codebook/14bit_MHD2_codebook.fasta','r') as input_handle:\n",
    "            for record in SeqIO.parse(input_handle, 'fasta'):\n",
    "                list_hamming.append(record.description.split())\n",
    "\n",
    "        df_hamming_codes=pd.DataFrame(list_hamming,columns=['R0','R1','R2','R3',\n",
    "                                                        'R4','R5','R6','R7',\n",
    "                                                        'R8','R9','R10','R11',\n",
    "                                                        'R12','R13'])\n",
    "    elif (bit=='16-bit'):\n",
    "        list_hamming=[]\n",
    "        with open('/home/dps/merfish/codebook/16bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            for record in SeqIO.parse(input_handle, 'fasta'):\n",
    "                list_hamming.append(record.description.split())\n",
    "\n",
    "        df_hamming_codes=pd.DataFrame(list_hamming,columns=['R0','R1','R2','R3',\n",
    "                                                        'R4','R5','R6','R7',\n",
    "                                                        'R8','R9','R10','R11',\n",
    "                                                        'R12','R13','R14','R15'])\n",
    "        \n",
    "    elif (bit=='18-bit'):\n",
    "        df_hamming_codes=pd.DataFrame(columns=['R0','R1','R2','R3',\n",
    "                                               'R4','R5','R6','R7',\n",
    "                                               'R8','R9','R10','R11',\n",
    "                                               'R12','R13','R14','R15',\n",
    "                                               'R16','R17'])\n",
    "        with open('/home/dps/merfish/codebook/18bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            df_hamming_codes=pd.read_csv(input_handle,delimeter=',')\n",
    "                \n",
    "    else:\n",
    "        df_hamming_codes=pd.DataFrame(columns=['R0','R1','R2','R3',\n",
    "                                               'R4','R5','R6','R7',\n",
    "                                               'R8','R9','R10','R11',\n",
    "                                               'R12','R13','R14','R15',\n",
    "                                               'R16','R17','R18','R19',\n",
    "                                               'R20','R21','R22','R23'])\n",
    "        with open('/home/dps/merfish/codebook/24bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            df_hamming_codes=pd.read_csv(input_handle,delimeter=',')\n",
    "            \n",
    "    return df_hamming_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding + readout assembly using Hamming codes (aka codebook)\n",
    "1. Create experiment specific codebook using two-colors, number of genes, and selected Hamming codes.\n",
    "2. Assemble encoding and readout probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateReadoutPlusEncoding(df_readout,df_encoding, df_hamming_codes, barcode_type, readout_type):\n",
    "    \n",
    "    # randomly assign genes to barcode sequences\n",
    "    number_of_barcode_seqs = len(df_hamming_codes)\n",
    "    gene_ids = df_encoding['gene'].unique()\n",
    "    number_of_genes=len(gene_ids)\n",
    "    barcode_seq_assignments=np.random.choice(number_of_barcode_seqs,number_of_genes,replace=False)\n",
    "    \n",
    "    if readout_type == 'amplified':\n",
    "        cols=df_readout.columns\n",
    "        df_readout = df_readout.drop(columns=[str(cols[1]),str(cols[2]), str(cols[3])])\n",
    "        df_readout = df_readout.rename(columns={str(cols[0]): 'sequence'})\n",
    "        df_readout.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    #create metadata\n",
    "    df_metadata = pd.DataFrame(columns=['gene','barcode ID','hamming type','readout type'])\n",
    "\n",
    "    df_encodingreadout = pd.DataFrame(columns=['probe','gene','sequence','isoform'])\n",
    "\n",
    "    # loop through all genes\n",
    "    for gene_id, assignment in zip(gene_ids,barcode_seq_assignments):\n",
    "\n",
    "        # load barcode sequence associated with this gene\n",
    "        bits = df_hamming_codes.iloc[assignment]\n",
    "\n",
    "        # extract encoding probes for this gene\n",
    "        df_gene = df_encoding[df_encoding['gene']==gene_id]\n",
    "        df_gene.reset_index(inplace=True)\n",
    "\n",
    "        # extract number of encoding probes and calculate halfway point\n",
    "        number_of_probes = len(df_gene['sequence'].unique())\n",
    "        halfway = number_of_probes//2\n",
    "\n",
    "        df_temp=pd.DataFrame(columns=['probe','gene','sequence','isoform'])\n",
    "\n",
    "        # loop over sequence\n",
    "        # place the first two bits on first half the probes (3' then 5')\n",
    "        # place the second two bits on second half the probes (3' then 5')\n",
    "        bit_placed=0\n",
    "        bit_counter=0\n",
    "        \n",
    "        for bit in bits:\n",
    "            if (np.int(bit)==1):\n",
    "                if bit_placed == 0:\n",
    "                    for i in range(0,halfway):\n",
    "                        df_temp=df_temp.append({'probe': i,\n",
    "                                                'gene': df_gene['gene'][i], \n",
    "                                                'sequence': df_readout['sequence'][np.int(bit_counter)] \n",
    "                                                    + 'A'+ df_gene['sequence'][i],\n",
    "                                                'isoform': df_gene['isoform'][i]},ignore_index=True)\n",
    "                    bit_placed=bit_placed+1\n",
    "                # should these be reverse complement? or just reverse?\n",
    "                elif bit_placed == 1:\n",
    "                    for i in range(0,halfway):\n",
    "                        df_temp=df_temp.append({'probe': i,\n",
    "                                                'gene': df_gene['gene'][i], \n",
    "                                                'sequence': df_gene['sequence'][i] \n",
    "                                                    + 'A'+ df_readout['sequence'][np.int(bit_counter)],\n",
    "                                                'isoform': df_gene['isoform'][i]},ignore_index=True)\n",
    "                    bit_placed=bit_placed+1\n",
    "                elif bit_placed == 2:\n",
    "                    for i in range(halfway,len(df_gene)):\n",
    "                        df_temp=df_temp.append({'probe': i,\n",
    "                                                'gene': df_gene['gene'][i], \n",
    "                                                'sequence': df_readout['sequence'][np.int(bit_counter)] \n",
    "                                                    + 'A' + df_gene['sequence'][i],\n",
    "                                                 'isoform': df_gene['isoform'][i]},ignore_index=True)\n",
    "                    bit_placed=bit_placed+1\n",
    "                # should these be reverse complement? or just reverse?\n",
    "                else:\n",
    "                    for i in range(halfway,len(df_gene)):\n",
    "                        df_temp=df_temp.append({'probe': i,\n",
    "                                                'gene': df_gene['gene'][i], \n",
    "                                                'sequence': df_gene['sequence'][i]\n",
    "                                                     + 'A'+ df_readout['sequence'][np.int(bit_counter)],\n",
    "                                                'isoform': df_gene['isoform'][i]},ignore_index=True)\n",
    "\n",
    "            bit_counter=bit_counter+1\n",
    "\n",
    "        df_encodingreadout = df_encodingreadout.append(df_temp)\n",
    "\n",
    "        # create metadata structure\n",
    "        df_metadata=df_metadata.append({'gene': gene_id, 'barcode ID': assignment,\n",
    "                                        'hamming type': barcode_type, 'readout type': readout_type},ignore_index=True)\n",
    "\n",
    "    df_encodingreadout.reset_index(inplace=True)\n",
    "    df_encodingreadout=df_encodingreadout.drop(columns=['index'])\n",
    "    \n",
    "    return df_encodingreadout, df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denovo primer design\n",
    "1. Read (or create) set of 20-mers from known set of 25-mers\n",
    "2. Select 20-mers that end in 'GC' or 'CG'\n",
    "3. Select 20-mers that do not contain triplet nucleotides\n",
    "4. Select 20-mers that have 40-50% GC\n",
    "5. Select 20-mers with Tm between 70 and 80C at 300 mM salt\n",
    "6. BLAST 20-mers against encoding+readout probes. Select all probes with less than 10 hits.\n",
    "7. BLAST 20-mers against lincRNA, rRNA, tRNA, mt-tRNA, mt-RNA for species of interest. Select all probes with less than 10 hits.\n",
    "8. Select forward and reverse primer based on minimum number of off-target hits.\n",
    "9. Save primers into Pandas structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePrimers(df_probes):\n",
    "    \n",
    "    # Make sure non-coding RNA database exists\n",
    "    fastaToBlastDBncRNA()\n",
    "\n",
    "    big_list_25mers_all = list(SeqIO.parse('bc25mer.240k.fasta','fasta'))\n",
    "    big_list_25mers=[]\n",
    "    \n",
    "    for i in range(0,len(big_list_25mers_all)):\n",
    "        big_list_25mers.append(str(big_list_25mers_all[i].seq))\n",
    "        \n",
    "    K=20\n",
    "    big_list_20mers=[]\n",
    "    \n",
    "    # Truncate 25-mers into 20-mers that have GC clamp\n",
    "    for trial_25mer in big_list_25mers:\n",
    "        trial_20mers = [trial_25mer[i: j] for i in range(len(trial_25mer)) for j in range(i + 1, len(trial_25mer) + 1) if len(trial_25mer[i:j]) == K]\n",
    "        for trial_20mer in trial_20mers:\n",
    "            if (trial_20mer.endswith('G') or trial_20mer.endswith('C') \n",
    "                or str(trial_20mer[:-1]).endswith('G') or str(trial_20mers[:-1]).endswith('C')):\n",
    "                    big_list_20mers.append(trial_20mer)\n",
    "    \n",
    "    # Check for triplets\n",
    "    pass_list=[]\n",
    "    for primer in big_list_20mers:\n",
    "        if not (('CCC' in primer) or ('TTT' in primer) or ('AAA' in primer) or ('GGG' in primer)):\n",
    "            pass_list.append(primer)\n",
    "    \n",
    "    # Check GC content\n",
    "    pass_list2=[]\n",
    "    for primer in pass_list:\n",
    "        gc_count = gcCheck(primer)\n",
    "        if (gc_count>=50) and (gc_count<=65):\n",
    "            pass_list2.append(primer)\n",
    "    \n",
    "    # Check melting temperature\n",
    "    pass_list3=[]\n",
    "    for primer in pass_list2:\n",
    "        tmval = mt.Tm_NN(primer,Na=390,dnac1=25,dnac2=0)        \n",
    "        if (tmval>=70.0) and (tmval<72.0):\n",
    "                pass_list3.append(primer)\n",
    "                \n",
    "    # BLAST against transcriptome\n",
    "    pass_list4=[]\n",
    "    for primer in pass_list3:\n",
    "\n",
    "        record = SeqRecord(Seq(primer,generic_dna),id=primer+'_'+str(i))\n",
    "        \n",
    "        with open('primer_test_h3g8.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='primer_test_h3g8.fasta',db='/home/dps/merfish/blastdb/hg38/GRCh38',\n",
    "                              out='primer_check_hg38.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('primer_check_hg38.xml','r') as input_handle_hg38:\n",
    "            blast_qresult = SearchIO.read(input_handle_hg38, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult:\n",
    "            if (hit.seq_len>=8) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list4.append(primer)\n",
    "    \n",
    "    # BLAST against non-coding RNA database\n",
    "    pass_list5=[]\n",
    "    first = True\n",
    "    for primer in pass_list4:\n",
    "\n",
    "        record = SeqRecord(Seq(primer,generic_dna),id=primer+'_'+str(i))\n",
    "        \n",
    "        with open('primer_test_ncRNA.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='primer_test_ncRNA.fasta',db='/home/dps/merfish/blastdb/tRNA/db/tRNA',\n",
    "                              out='primer_check_ncRNA.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('primer_check_ncRNA.xml','r') as input_handle_ncRNA:\n",
    "            blast_qresult_ncRNA = SearchIO.read(input_handle_ncRNA, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_ncRNA:\n",
    "            if (hit.seq_len>=8) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list5.append(primer)\n",
    "\n",
    "    # create BLASTDB for remaining primers\n",
    "    for primer in pass_list5:\n",
    "        \n",
    "        record = SeqRecord(Seq(primer,generic_dna),id=primer+'_'+str(i),description=\"potential_primer_\"+str(i))\n",
    "\n",
    "        with open('/home/dps/merfish/blastdb/primer/primer_candidates.fasta','a') as output_handle:    \n",
    "            SeqIO.write(record,output_handle,\"fasta\")\n",
    "\n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/primer/primer_candidates.fasta',\n",
    "                                       title='primer',out='/home/dps/merfish/blastdb/primer/db/primer')\n",
    "    stdout, stderr = cline()\n",
    "    \n",
    "    # BLAST against remaining primer list\n",
    "    pass_list6=[]\n",
    "    for primer in pass_list5:\n",
    "\n",
    "        record = SeqRecord(Seq(primer,generic_dna),id=primer+'_'+str(i))\n",
    "        \n",
    "        with open('primer_test_final.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='primer_test_final.fasta',db='/home/dps/merfish/blastdb/primer/db/primer',\n",
    "                              out='primer_test_final.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('primer_test_final.xml','r') as input_handle_final:\n",
    "            blast_qresult_final = SearchIO.read(input_handle_final, 'blast-xml')\n",
    "        \n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_final:\n",
    "            if (hit.seq_len>=8) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list6.append(primer)\n",
    "            \n",
    "    # Create BLASTDB \n",
    "    extracted_probes = df_probes[\"sequence\"]\n",
    "    for probe in extracted_probes:\n",
    "        \n",
    "        record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i),description=\"probe_\"+str(i))\n",
    "        \n",
    "        with open('/home/dps/merfish/blastdb/probes/probe_list.fasta','a') as output_handle:    \n",
    "            SeqIO.write(record,output_handle,\"fasta\")\n",
    "\n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/probes/probe_list.fasta',\n",
    "                                       title='probes',out='/home/dps/merfish/blastdb/probes/db/probes')\n",
    "    stdout, stderr = cline()\n",
    "    \n",
    "    # BLAST against encoding+readout probe constructs\n",
    "    pass_list7=[]\n",
    "    for primer in pass_list5:\n",
    "\n",
    "        record = SeqRecord(Seq(primer,generic_dna),id=primer+'_'+str(i))\n",
    "        \n",
    "        with open('primer_test_probes.fasta','w') as output_handle:\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "                \n",
    "        blastn_cline = blastn(query='primer_test_probes.fasta',db='/home/dps/merfish/blastdb/probes/db/probes',\n",
    "                              out='primer_test_probes.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('primer_test_probes.xml','r') as input_handle_final:\n",
    "            blast_qresult_final = SearchIO.read(input_handle_final, 'blast-xml')\n",
    "        \n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_final:\n",
    "            if (hit.seq_len>=8) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list7.append(primer)\n",
    "            \n",
    "    \n",
    "    # place each probe in dataframe \n",
    "    df_primers = pd.DataFrame(columns=['primer','sequence'])\n",
    "    i=0\n",
    "    for primers in pass_list7:\n",
    "        df_primers = df_readout.append({'primer': i, 'sequence': probe},ignore_index=True)\n",
    "        i+=1\n",
    "        \n",
    "    return df_primers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add primers, T7 promoter, and linkers to encoding + readout probe sequences for ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if potential primers dataframe is saved to disk\n",
    "# if true, load it\n",
    "# if not, generate it (need to add checks?)\n",
    "df_primers_list = generatePrimers(df_readout_probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructFullProbes(df_encodingreadout,df_primers):\n",
    "    \n",
    "    return df_fullprobes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define probe set parameters\n",
    "- hamming code strategy (14-bit,16-bit,18-bit,24-bit)\n",
    "- readout strategy (sequential,barcode) AND (denovo, Moffitt, Moffitt amplified)\n",
    "  - if sequential, need to define number of colors per round\n",
    "- genome (hg38. TO DO: add support for rat and mouse)\n",
    "- genes of interest (TO DO: add support for reading in from file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr22\n",
      "chr22\n",
      "chr22\n",
      "chr22\n",
      "chr1\n",
      "chr1\n",
      "chr1\n",
      "chr1\n",
      "chr1\n",
      "chr1\n",
      "chr1\n",
      "chr1\n",
      "chr5\n",
      "chr5\n",
      "chr5\n",
      "chr5\n",
      "chr16\n",
      "chr16\n",
      "chr16\n",
      "chr16\n"
     ]
    }
   ],
   "source": [
    "# define barcode strategy\n",
    "hamming_bit = '16-bit'\n",
    "\n",
    "# define readout probe strategy\n",
    "readout_strategy = ['barcode','amplified']\n",
    "\n",
    "# define target genome\n",
    "genome = 'hg38'\n",
    "\n",
    "# define target genes\n",
    "# use refGene ID is UCSC\n",
    "# TO DO: create function to parse & load output of gene selection software\n",
    "gene_ids=['CLDN5','PTPRC','PDGFRB','CDH1']\n",
    "\n",
    "if readout_strategy[0]=='sequential':\n",
    "    df_barcodes = createSequentialCodes(readout_strategy[2])\n",
    "# load modified hamming codes\n",
    "else:\n",
    "    df_barcodes = loadHammingFromDisk(hamming_bit)\n",
    "\n",
    "# load (or generate) readout probe sequences\n",
    "df_readout_probes = loadReadoutProbes(readout_strategy[1])\n",
    "\n",
    "# generate encoding probe sequences\n",
    "df_encoding_probes = generateEncodingProbes(genome,gene_ids)\n",
    "\n",
    "# generate encoding+readout probe sequences using codebook\n",
    "df_encoding_readout_probes, df_metadata = generateReadoutPlusEncoding(df_readout_probes,df_encoding_probes,df_barcodes,hamming_bit,readout_strategy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate forward and reverse primer sequences for this set of encoding+readout probes\n",
    "df_primers = generatePrimers(df_encoding_readout_probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full probe sequences for ordering\n",
    "df_full_probes = constructFullProbes(df_encoding_readout_probes,df_primers):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all dataframes to disk with unique identifier and all settings needed to regenerate workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write encoding probes\n",
    "\n",
    "# write readout probes\n",
    "\n",
    "# write hamming codes\n",
    "\n",
    "# write primers\n",
    "\n",
    "# write full probes (T7, primers, encoding, readout)\n",
    "\n",
    "# write metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
